{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv0Prbkh9VXz"
      },
      "outputs": [],
      "source": [
        "#Model.py\n",
        "#We use paded convolutions\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class DoubleConv(nn.module):\n",
        "  def __init__ (self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias = False), #(in channel, out channel, kernel size, stride, padding(1 for same padding), bias)\n",
        "        nn.BatchNorm2d(out_channels), # as we use batchnorm the bias will cansel so we dont use bias in our convolution\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace = True),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class unet (nn.Module):\n",
        "  def __init__ (self, in_channels=3, out_channels= 1, features=[64, 128, 256, 512]): #we have RGB immages so in chnnaels is 3 and a binary classifier so out channel is 1 features is the number of featurs in each stage convolution layer\n",
        "    super(unet, self).__init__()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    #down part of u-net\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channel, feature))\n",
        "      in_channels = feature\n",
        "\n",
        "    #up part of u-net\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size = 2, stride = 2)) #up conves in paper\n",
        "      self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "    self.finalconv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forrward(self, x):\n",
        "      skip_connections = []\n",
        "      for down in downs:\n",
        "        x = downs(x)\n",
        "        skip_connections.append(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        \n",
        "      x = self.bottleneck(x)\n",
        "      skip_connections = skip_connections[::-1]\n",
        "      for idx in range(0, len(self.ups), 2):\n",
        "        x = self.ups[idx](x) #this is the up sampling applyed on x\n",
        "        skip_connection = skip_connections[idx//2]\n",
        "        \n",
        "        if x.shape != skip_connection.shape:\n",
        "          x= TF.resize(x, size = skip_connection[2:]) #we just get its height and width\n",
        "\n",
        "        concat_skip = torch.cat((skip_connection, x), dim = 1) #we add them along the channel dimention (batch, channel, height, width)\n",
        "        x = self.ups[idx+1](concat_skip) #this is doubleconves appled on concatinat data (x + skip_connection)\n",
        "\n",
        "      return self.finalconv(x)"
      ]
    }
  ]
}
